{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375aa2ac",
   "metadata": {},
   "source": [
    "# **Entering Training Stage**\n",
    "\n",
    "# Lecture 26: Measuring the Loss\n",
    "\n",
    "### Overview over different Loss functions for different task\n",
    "#### https://blog.dailydoseofds.com/p/10-most-common-and-must-know-loss\n",
    "\n",
    "### finding the loss between the targets (given values) and the outputs (predicted values)\n",
    "\n",
    "### reducing the context length for the training stage in order to reduce computational resource requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dde7d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from model_with_feature_classes import GPTModel\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fba1d520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d80f6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bce49d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a29f3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdims=True)\n",
    "\n",
    "        idx = torch.cat((idx.to(device), idx_next.to(device)), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "063a510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(f\"Output text:\\n {token_ids_to_text(token_ids, tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22f9fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],\n",
    "                       [40, 1107, 588]])\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],\n",
    "                        [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9af1956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([2, 3]) Inputs flatten shape: torch.Size([1, 6])\n",
      "Targets shape: torch.Size([2, 3]) Targets flatten shape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inputs shape: {inputs.shape} Inputs flatten shape: {inputs.flatten(0, 1).unsqueeze(0).shape}\")\n",
    "print(f\"Targets shape: {targets.shape} Targets flatten shape: {targets.flatten(0, 1).unsqueeze(0).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "108cd01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs.to(device))\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8547b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdims=True)\n",
    "\n",
    "print(f\"Token IDs:\\n {token_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76516dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e667a83",
   "metadata": {},
   "source": [
    "## Cross-entropy loss\n",
    "\n",
    "### get the target indices from the probabilities tensor and find the values that correspond to the indices\n",
    "\n",
    "### goal of the training is to get these probabilities as close to 1 as possible \n",
    "\n",
    "### 1) logits\n",
    "\n",
    "### 2) probabilities\n",
    "\n",
    "### 3) target probabilities\n",
    "\n",
    "### 4) log probabilities\n",
    "\n",
    "### 5) average log probability\n",
    "\n",
    "### 6) negative average log probability\n",
    "\n",
    "### ---> cross entropy loss (negative log likelyhood) ---> minimize this value as much as possible ---> measuring the difference between 2 probaility distributions\n",
    "\n",
    "## logits for 2 batches 2 X 3 X 50257 ---> flatten(0, 1) ---> 6 X 50257 merge first two dimensions\n",
    "\n",
    "## negative loglikelyhood --> logarithm of probabilities given by the llm as output , taken the mean and the negative of that value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "07add651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05], device='mps:0')\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(f\"Text 1: {target_probas_1}\")\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(f\"Text 2: {target_probas_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "835a9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561],\n",
      "       device='mps:0')\n",
      "tensor(-10.7940, device='mps:0')\n",
      "tensor(10.7940, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "neg_avg_log_probas = avg_log_probas * (-1)\n",
    "\n",
    "print(log_probas)\n",
    "print(avg_log_probas)\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b397b667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Logits: torch.Size([6, 50257])\n",
      "Flattened Targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(f\"Flattened Logits: {logits_flat.shape}\")\n",
    "print(f\"Flattened Targets: {targets_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87dddad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7940, device='mps:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat.to(device), targets_flat.to(device))\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc15370",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2dd0e6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48725.8203, device='mps:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd45eaad",
   "metadata": {},
   "source": [
    "### model is as uncertain as if i had to choose the next token from 48725 tokens from the vocabulary\n",
    "\n",
    "### relates directly to the vocabulary size of size 50257 tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_built_steps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

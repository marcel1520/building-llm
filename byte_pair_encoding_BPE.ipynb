{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4f902fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad1d952",
   "metadata": {},
   "source": [
    "### ---> reading a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54405384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good\n"
     ]
    }
   ],
   "source": [
    "def read_txt_file(name, method):\n",
    "    with open(name, method) as f:\n",
    "        corpus = f.read()\n",
    "    return corpus\n",
    "\n",
    "the_verdict = read_txt_file(\"the-verdict.txt\", \"r\")\n",
    "print(the_verdict[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56d0092",
   "metadata": {},
   "source": [
    "### ---> creating vocabulary with unique words and chars (Word based tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5884d0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size Word based: 1130\n"
     ]
    }
   ],
   "source": [
    "def word_based_vocab(text):\n",
    "    word_content = []\n",
    "    split_words = re.split(r'([.,:;!_?()\"\\']|--|\\s)', text)\n",
    "    for cont in split_words:\n",
    "        if cont.strip():\n",
    "            word_content.append(cont.strip())\n",
    "    word_vocab = sorted(set(word_content))\n",
    "    return word_vocab\n",
    "\n",
    "word__based_vocab = word_based_vocab(the_verdict)\n",
    "print(f\"Vocabulary Size Word based: {len(word__based_vocab)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573410e",
   "metadata": {},
   "source": [
    "### ---> creating vocabulary with unique chars (Character based tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "afbd8f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size Character based: 60\n"
     ]
    }
   ],
   "source": [
    "def character_based_vocab(text):\n",
    "    corpus_pre = re.split(r'([.,:;!_?()\"\\']|--|\\s)', text)\n",
    "    corpus_pre_1 = []\n",
    "    char_content = []\n",
    "    for word in corpus_pre:\n",
    "        if word.strip():\n",
    "            corpus_pre_1.append(word.strip())\n",
    "    unique_corpus_pre1 = set(corpus_pre_1)\n",
    "    unique_corpus = list(unique_corpus_pre1)\n",
    "    for item in unique_corpus:\n",
    "        for char in item:\n",
    "            char_content.append(char)\n",
    "    all_chars_unique = sorted(set(char_content))\n",
    "    return all_chars_unique, corpus_pre_1\n",
    "\n",
    "character__based_vocab, corpus__pre_1 = character_based_vocab(the_verdict)\n",
    "print(f\"Vocabulary Size Character based: {len(character__based_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a2c65",
   "metadata": {},
   "source": [
    "### ---> mapping chars and their frequencies in word context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2272f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_mapping(word_list):\n",
    "    freq_mapping = {}\n",
    "    end_of_word = \"</w>\"\n",
    "    for word in word_list:\n",
    "        if word:\n",
    "            char_list = list(word) + [end_of_word]\n",
    "            chars_tuple = tuple(char_list)\n",
    "            if chars_tuple in freq_mapping:\n",
    "                freq_mapping[chars_tuple] += 1\n",
    "            else:\n",
    "                freq_mapping[chars_tuple] = 1\n",
    "    return freq_mapping\n",
    "\n",
    "freq__mapping = freq_mapping(corpus__pre_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e7e2d",
   "metadata": {},
   "source": [
    "### ---> get char pairs and their frequencies using defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b580027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_frequenciesV1(word_dict):\n",
    "    pair_counts = collections.defaultdict(int)\n",
    "    for word, freq in word_dict.items():\n",
    "        split_words = list(word)\n",
    "        for i in range(len(split_words) - 1):\n",
    "            pair = (split_words[i], split_words[i+1])\n",
    "            pair_counts[pair] += freq\n",
    "    return pair_counts\n",
    "\n",
    "pair_frequenciesV1 = get_pair_frequenciesV1(freq__mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef41c2",
   "metadata": {},
   "source": [
    "### ---> get char pairs and their frequencies using regular dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b9a323fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('e', '</w>')\n",
      "Number of occurrences: 729\n"
     ]
    }
   ],
   "source": [
    "def get_pair_frequenciesV2(word_dict):  \n",
    "    pair_counts = {}\n",
    "    for word, freq in word_dict.items():\n",
    "        split_words = list(word)\n",
    "        for i in range(len(split_words) - 1):\n",
    "            pair = (split_words[i], split_words[i+1])\n",
    "            if pair not in pair_counts.keys():\n",
    "                pair_counts[pair] = freq\n",
    "            else:\n",
    "                pair_counts[pair] += freq\n",
    "    return pair_counts\n",
    "\n",
    "pair_frequenciesV2 = get_pair_frequenciesV2(freq__mapping)\n",
    "\n",
    "best_pair = max(pair_frequenciesV2, key=pair_frequenciesV2.get)\n",
    "print(f\"Most frequent pair: {best_pair}\")\n",
    "best_freq = pair_frequenciesV2[best_pair]\n",
    "print(f\"Number of occurrences: {best_freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa842e54",
   "metadata": {},
   "source": [
    "### ---> merge one pair from frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b8f21f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(pair_to_merge, new_mapping):\n",
    "    mapping = {}\n",
    "    (first, second) = pair_to_merge\n",
    "    merged_token = first + second\n",
    "    for word_tuple, freq in new_mapping.items():\n",
    "        chars = list(word_tuple)\n",
    "        new_chars = []\n",
    "        i = 0\n",
    "        while i < len(word_tuple):\n",
    "            if i < len(chars) - 1 and chars[i] == first and chars[i+1] == second:\n",
    "                new_chars.append(merged_token)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_chars.append(chars[i])\n",
    "                i += 1\n",
    "        mapping[tuple(new_chars)] = freq\n",
    "    return mapping\n",
    "\n",
    "pair_merge = merge_pair((\"I\", \"</w>\"), freq__mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6d31c",
   "metadata": {},
   "source": [
    "### ---> merging loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b8b5036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_merges = 40\n",
    "merges = {}\n",
    "current_splits = freq__mapping.copy()\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pair_stats = get_pair_frequenciesV1(current_splits)\n",
    "    if not pair_stats:\n",
    "        print(\"No more pairs to merge\")\n",
    "        break\n",
    "\n",
    "    best_pair = max(pair_stats, key=pair_stats.get)\n",
    "    best_freq = pair_stats[best_pair]\n",
    "    \n",
    "    current_splits = merge_pair(best_pair, current_splits)\n",
    "    new_token = best_pair[0] + best_pair[1]\n",
    "    \n",
    "    character__based_vocab.append(new_token)\n",
    "    merges[best_pair] = new_token\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9069ce3",
   "metadata": {},
   "source": [
    "### ---> results overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f05ccd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BPE Merges Complete ---\n",
      "Final Vocabulary Size 100\n",
      "\n",
      "Learned Merges (Pair -> New Token):\n",
      "('e', '</w>') -> 'e</w>'\n",
      "('t', '</w>') -> 't</w>'\n",
      "('d', '</w>') -> 'd</w>'\n",
      "('s', '</w>') -> 's</w>'\n",
      "('t', 'h') -> 'th'\n",
      "('n', '</w>') -> 'n</w>'\n",
      "('y', '</w>') -> 'y</w>'\n",
      "('i', 'n') -> 'in'\n",
      "(',', '</w>') -> ',</w>'\n",
      "('.', '</w>') -> '.</w>'\n",
      "('o', 'u') -> 'ou'\n",
      "('e', 'r') -> 'er'\n",
      "('e', 'd</w>') -> 'ed</w>'\n",
      "('th', 'e</w>') -> 'the</w>'\n",
      "('o', '</w>') -> 'o</w>'\n",
      "('a', 'n') -> 'an'\n",
      "('f', '</w>') -> 'f</w>'\n",
      "('\"', '</w>') -> '\"</w>'\n",
      "('h', 'a') -> 'ha'\n",
      "('in', 'g') -> 'ing'\n",
      "('I', '</w>') -> 'I</w>'\n",
      "('h', 'i') -> 'hi'\n",
      "('ing', '</w>') -> 'ing</w>'\n",
      "('h', 'e</w>') -> 'he</w>'\n",
      "('o', 'n') -> 'on'\n",
      "('t', 'o</w>') -> 'to</w>'\n",
      "('w', 'a') -> 'wa'\n",
      "('o', 'f</w>') -> 'of</w>'\n",
      "('-', '-') -> '--'\n",
      "('--', '</w>') -> '--</w>'\n",
      "('o', 'r') -> 'or'\n",
      "('a', '</w>') -> 'a</w>'\n",
      "(\"'\", '</w>') -> ''</w>'\n",
      "('e', 'a') -> 'ea'\n",
      "('an', 'd</w>') -> 'and</w>'\n",
      "('s', 't') -> 'st'\n",
      "('e', 'n') -> 'en'\n",
      "('er', '</w>') -> 'er</w>'\n",
      "('u', 'r') -> 'ur'\n",
      "('a', 't</w>') -> 'at</w>'\n",
      "\n",
      "Final Vocabulary (sorted):\n",
      "['!', '\"', '\"</w>', \"'\", \"'</w>\", '(', ')', ',', ',</w>', '-', '--', '--</w>', '.', '.</w>', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'I</w>', 'J', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', '_', 'a', 'a</w>', 'an', 'and</w>', 'at</w>', 'b', 'c', 'd', 'd</w>', 'e', 'e</w>', 'ea', 'ed</w>', 'en', 'er', 'er</w>', 'f', 'f</w>', 'g', 'h', 'ha', 'he</w>', 'hi', 'i', 'in', 'ing', 'ing</w>', 'j', 'k', 'l', 'm', 'n', 'n</w>', 'o', 'o</w>', 'of</w>', 'on', 'or', 'ou', 'p', 'q', 'r', 's', 's</w>', 'st', 't', 't</w>', 'th', 'the</w>', 'to</w>', 'u', 'ur', 'v', 'w', 'wa', 'x', 'y', 'y</w>', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- BPE Merges Complete ---\")\n",
    "print(f\"Final Vocabulary Size {len(character__based_vocab)}\")\n",
    "print(\"\\nLearned Merges (Pair -> New Token):\")\n",
    "\n",
    "for pair, token in merges.items():\n",
    "    print(f\"{pair} -> '{token}'\")\n",
    "\n",
    "print(\"\\nFinal Vocabulary (sorted):\")\n",
    "\n",
    "final_vocab_sorted = sorted(list(set(character__based_vocab)))\n",
    "print(final_vocab_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_built_steps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

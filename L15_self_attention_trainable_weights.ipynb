{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61e20a9",
   "metadata": {},
   "source": [
    "# Lecture 15: Self-Attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "80730c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "inputs = torch.tensor([[0.43, 0.15, 0.89],\n",
    "                       [0.55, 0.87, 0.66],\n",
    "                       [0.57, 0.85, 0.64],\n",
    "                       [0.22, 0.58, 0.33],\n",
    "                       [0.77, 0.25, 0.10],\n",
    "                       [0.05, 0.80, 0.55]]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e463c71",
   "metadata": {},
   "source": [
    "### defining variables for creating Query, Key and Value Weight Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16581ee1",
   "metadata": {},
   "source": [
    "*Input Dimension* = 3 , *Output Dimension* = 2\n",
    "\n",
    "### Input Dimension has to match in order to follow the rules of Matrix Multiplication --> Rows of trainable weight matrices have to match the columns (Dimensions) of the input Vector Embeddings or the Inputs Matrix\n",
    "### Ensuring the Inner Dimensions match during Matrix Multiplication the Output Dimension can be anything\n",
    "\n",
    "### in the Example below the initial Dimension of the Inputs Matrix is changed from 3 to 2 as the trainable weight matrices are chosen to have a dimension of 2 (2 Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "c030e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce14ab8",
   "metadata": {},
   "source": [
    "### building weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2ce80458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "tensor([[0.4300, 0.1500, 0.8900],\n",
      "        [0.5500, 0.8700, 0.6600],\n",
      "        [0.5700, 0.8500, 0.6400],\n",
      "        [0.2200, 0.5800, 0.3300],\n",
      "        [0.7700, 0.2500, 0.1000],\n",
      "        [0.0500, 0.8000, 0.5500]])torch.Size([6, 3])\n",
      "\n",
      "W_query Weight Matrix:\n",
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])torch.Size([3, 2])\n",
      "\n",
      "W_key Weight Matrix:\n",
      "Parameter containing:\n",
      "tensor([[0.1366, 0.1025],\n",
      "        [0.1841, 0.7264],\n",
      "        [0.3153, 0.6871]])torch.Size([3, 2])\n",
      "\n",
      "W_Value Weight Matrix:\n",
      "Parameter containing:\n",
      "tensor([[0.0756, 0.1966],\n",
      "        [0.3164, 0.4017],\n",
      "        [0.1186, 0.8274]])torch.Size([3, 2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "print(f\"Inputs:\\n{inputs}{inputs.shape}\\n\")\n",
    "\n",
    "print(f\"W_query Weight Matrix:\\n{W_query}{W_query.shape}\\n\")\n",
    "print(f\"W_key Weight Matrix:\\n{W_key}{W_key.shape}\\n\")\n",
    "print(f\"W_Value Weight Matrix:\\n{W_value}{W_value.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330004cc",
   "metadata": {},
   "source": [
    "### computing QUERIES, KEYS and VALUES Matrices for the word \"Journey\" from Input Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "fbfeb6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Matrix for word Journey:\n",
      "tensor([0.4306, 1.4551])\n",
      "torch.Size([2])\n",
      "\n",
      "Key Matrix for word Journey:\n",
      "tensor([0.4433, 1.1419])\n",
      "torch.Size([2])\n",
      "\n",
      "Values Matrix for word Journey\n",
      "tensor([0.3951, 1.0037])\n",
      "torch.Size([2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "\n",
    "print(f\"Query Matrix for word Journey:\\n{query_2}\\n{query_2.shape}\\n\")\n",
    "print(f\"Key Matrix for word Journey:\\n{key_2}\\n{key_2.shape}\\n\")\n",
    "print(f\"Values Matrix for word Journey\\n{value_2}\\n{value_2.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba8fc7",
   "metadata": {},
   "source": [
    "### computing the Queries, Keys and Values Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a02e2585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries:\n",
      "tensor([[0.2309, 1.0966],\n",
      "        [0.4306, 1.4551],\n",
      "        [0.4300, 1.4343],\n",
      "        [0.2355, 0.7990],\n",
      "        [0.2983, 0.6565],\n",
      "        [0.2568, 1.0533]])torch.Size([6, 2])\n",
      "\n",
      "Keys:\n",
      "tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1827, 0.3292],\n",
      "        [0.3275, 0.9642]])torch.Size([6, 2])\n",
      "Values:\n",
      "tensor([[0.1855, 0.8812],\n",
      "        [0.3951, 1.0037],\n",
      "        [0.3879, 0.9831],\n",
      "        [0.2393, 0.5493],\n",
      "        [0.1492, 0.3346],\n",
      "        [0.3221, 0.7863]])torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "queries = inputs @ W_query\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "\n",
    "print(f\"Queries:\\n{queries}{queries.shape}\\n\")\n",
    "print(f\"Keys:\\n{keys}{keys.shape}\")\n",
    "print(f\"Values:\\n{values}{values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aecbe2",
   "metadata": {},
   "source": [
    "### computing attention scores for Journey, working with the *Queries* Matrix and the *Keys* Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "cfafe82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) @ torch.Size([2, 6]) --> 1 X 6 Vector\n",
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440]) | torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "token_2 = queries[1]\n",
    "\n",
    "attn_scores_2 = token_2 @ keys.T\n",
    "print(f\"{token_2.shape} @ {keys.T.shape} --> 1 X 6 Vector\")\n",
    "print(f\"{attn_scores_2} | {attn_scores_2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100542d",
   "metadata": {},
   "source": [
    "### computing all attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e99439d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2]) @ torch.Size([2, 6]) = torch.Size([6, 6])\n",
      "Attention Scores:\n",
      "tensor([[0.9231, 1.3545, 1.3241, 0.7910, 0.4032, 1.1330],\n",
      "        [1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440],\n",
      "        [1.2544, 1.8284, 1.7877, 1.0654, 0.5508, 1.5238],\n",
      "        [0.6973, 1.0167, 0.9941, 0.5925, 0.3061, 0.8475],\n",
      "        [0.6114, 0.8819, 0.8626, 0.5121, 0.2707, 0.7307],\n",
      "        [0.8995, 1.3165, 1.2871, 0.7682, 0.3937, 1.0996]])torch.Size([6, 6])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = queries @ keys.T\n",
    "print(f\"{queries.shape} @ {keys.T.shape} = {attn_scores.shape}\")\n",
    "print(f\"Attention Scores:\\n{attn_scores}{attn_scores.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345f481",
   "metadata": {},
   "source": [
    "### scaling by the square root of the keys dimension (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41f261",
   "metadata": {},
   "source": [
    "#### prevents the values which are optained after application of softmax to become peaky as well as to keep the variance closer to value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c8d035e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores: scaled by square root of 2\n",
      "tensor([[0.6528, 0.9578, 0.9363, 0.5593, 0.2851, 0.8011],\n",
      "        [0.8984, 1.3098, 1.2806, 0.7633, 0.3944, 1.0918],\n",
      "        [0.8870, 1.2929, 1.2641, 0.7534, 0.3895, 1.0775],\n",
      "        [0.4930, 0.7189, 0.7029, 0.4190, 0.2164, 0.5993],\n",
      "        [0.4323, 0.6236, 0.6099, 0.3621, 0.1914, 0.5167],\n",
      "        [0.6361, 0.9309, 0.9101, 0.5432, 0.2784, 0.7776]])\n"
     ]
    }
   ],
   "source": [
    "scaled_attn_scores = attn_scores / torch.sqrt(torch.tensor(keys.shape[-1]))\n",
    "print(f\"Attention Scores: scaled by square root of 2\\n{scaled_attn_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd9fe8",
   "metadata": {},
   "source": [
    "### taking the softmax in order to favour interpretability and improve backpropagationtraing stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "128e8ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights: normalized along the Rows:\n",
      "tensor([[0.1551, 0.2104, 0.2059, 0.1413, 0.1074, 0.1799],\n",
      "        [0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820],\n",
      "        [0.1503, 0.2256, 0.2192, 0.1315, 0.0914, 0.1819],\n",
      "        [0.1591, 0.1994, 0.1962, 0.1477, 0.1206, 0.1769],\n",
      "        [0.1610, 0.1949, 0.1923, 0.1501, 0.1265, 0.1752],\n",
      "        [0.1557, 0.2092, 0.2048, 0.1419, 0.1089, 0.1794]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(scaled_attn_scores, dim=-1)\n",
    "print(f\"Attention Weights: normalized along the Rows:\\n{attn_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5ebad",
   "metadata": {},
   "source": [
    "### computing one context vector for the word Journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "fe76e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6]) @ torch.Size([6, 2]) --> torch.Size([2])\n",
      "Context Vector'Journey':\n",
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "attn_journey = attn_weights[1]\n",
    "context_journey = attn_journey @ values\n",
    "print(f\"{attn_journey.shape} @ {values.shape} --> {context_journey.shape}\")\n",
    "print(f\"Context Vector'Journey':\\n{context_journey}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7703d71",
   "metadata": {},
   "source": [
    "### computing all context vectors by multiplying the attention weights matrix with the values matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "d7243f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6]) @ torch.Size([6, 2]) --> torch.Size([6, 2])\n",
      "Context Vectors:\n",
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]])\n"
     ]
    }
   ],
   "source": [
    "context_matrix = attn_weights @ values\n",
    "print(f\"{attn_weights.shape} @ {values.shape} --> {context_matrix.shape}\")\n",
    "print(f\"Context Vectors:\\n{context_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf1d79",
   "metadata": {},
   "source": [
    "## Self Attention Class V1 -- using nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "507a3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        queries = x @ self.W_query\n",
    "        keys = x @ self.W_key\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights_scaled = attn_scores / torch.sqrt(torch.tensor(keys.shape[-1]))\n",
    "        attn_weights = torch.softmax(attn_weights_scaled, dim=-1)\n",
    "\n",
    "        context_matrix = attn_weights @ values\n",
    "        return context_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5b377",
   "metadata": {},
   "source": [
    "### creating an instance of the self attention v1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1cbbc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vectors:\n",
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "self_attention_v1 = SelfAttentionV1(d_in, d_out)\n",
    "print(f\"Context Vectors:\\n{self_attention_v1.forward(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c940a8",
   "metadata": {},
   "source": [
    "# Self Attention Calss V2 -- using nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7485e76",
   "metadata": {},
   "source": [
    "#### nn.Linear has an optimized weight initialization schema which leads to more stable and effective model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b3c107c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights_scaled = attn_scores / torch.sqrt(torch.tensor(keys.shape[-1]))\n",
    "        attn_weights = torch.softmax(attn_weights_scaled, dim=-1)\n",
    "\n",
    "        context_matrix = attn_weights @ values\n",
    "        return context_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a247be",
   "metadata": {},
   "source": [
    "### creating an instance of the self attention v2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e2953b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Matrix:\n",
      "tensor([[0.2461, 0.2370],\n",
      "        [0.2437, 0.2398],\n",
      "        [0.2438, 0.2398],\n",
      "        [0.2437, 0.2368],\n",
      "        [0.2455, 0.2362],\n",
      "        [0.2429, 0.2379]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(78)\n",
    "self_attention_v2 = SelfAttentionV2(d_in, d_out)\n",
    "print(f\"Context Matrix:\\n{self_attention_v2.forward(inputs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_built_steps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

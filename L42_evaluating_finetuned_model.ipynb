{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59f70169",
   "metadata": {},
   "source": [
    "# L 42 Evaluating fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0c6f686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20e26bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c15ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f675b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_with_feature_classes_1 import GPTModel\n",
    "import helper_functions_for_finetuning\n",
    "from helper_functions_for_finetuning import InstructionDataset, format_input, custom_collate_fn\n",
    "import tiktoken\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8895be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5152053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25}\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[\"gpt2-large (774M)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20f346f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_emb): Embedding(50257, 1280)\n",
       "  (pos_emb): Embedding(1024, 1280)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (24): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (25): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (26): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (27): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (28): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (29): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (30): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (31): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (32): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (33): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (34): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (35): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_key): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (W_value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feedforw): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (Layernorm1): LayerNorm()\n",
       "      (Layernorm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "model.load_state_dict(torch.load(\"gpt2-large774M-sft.pt\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "336b6124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists.\n"
     ]
    }
   ],
   "source": [
    "url_orig = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch07/01_main-chapter-code/previous_chapters.py\"\n",
    "res_orig = requests.get(url_orig)\n",
    "\n",
    "location = \"/Users/marcelmann/VisualStudioProjects/llm-model-building-steps\"\n",
    "file_name = \"previous_chapters.py\"\n",
    "\n",
    "full_path = os.path.join(location, file_name)\n",
    "\n",
    "if os.path.exists(full_path):\n",
    "    print(\"file already exists.\")\n",
    "else:\n",
    "    with open(\"previous_chapters.py\", \"wb\") as file:\n",
    "        file.write(res_orig.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "514fd51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    }
   ],
   "source": [
    "def download_dataset(file_path, url):\n",
    "  ssl_context = ssl.create_default_context()\n",
    "  ssl_context.check_hostname = False\n",
    "  ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "  if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "      text_data = response.read().decode(\"utf-8\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "      file.write(text_data)\n",
    "\n",
    "  else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "      text_data = file.read()\n",
    "\n",
    "  with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url_instr = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_dataset(file_path, url_instr)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bc38fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935\n",
      "110\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "train_part = int(len(data) * 0.85)\n",
    "test_part = int(len(data) * 0.1)\n",
    "valid_part = len(data) - train_part - test_part\n",
    "\n",
    "train_data = data[:train_part]\n",
    "test_data = data[train_part:train_part+test_part]\n",
    "valid_data = data[train_part+test_part:]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ec7a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import previous_chapters\n",
    "from previous_chapters import generate, token_ids_to_text, text_to_token_ids\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6b38528",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "683219e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropiately completes the request.\n",
      "\n",
      "### Instruction\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct Response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model Response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------\n",
      "Below is an instruction that describes a task. Write a response that appropiately completes the request.\n",
      "\n",
      "### Instruction\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct Response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model Response:\n",
      ">> A thunderstorm is a type of cloud.\n",
      "-------\n",
      "Below is an instruction that describes a task. Write a response that appropiately completes the request.\n",
      "\n",
      "### Instruction\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct Response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model Response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect Response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel Response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "208a9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_resp = \"https://raw.githubusercontent.com/JohnMachado11/Build-a-Large-Language-Model-from-Scratch/2c14e7960c7051e3d563e17fb092e9c11d36b46b/07_Fine_tuning_for_instructions/7.8_Evaluating_the_fine_tuned_LLM/instruction-data-with-response.json\"\n",
    "res_resp = requests.get(url_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [1:20:52<00:00, 44.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Rewrite the sentence using a simile.',\n",
       "  'input': 'The car is very fast.',\n",
       "  'output': 'The car is as fast as lightning.',\n",
       "  'model_response': 'The car is as fast as a cheetah.'},\n",
       " {'instruction': 'What type of cloud is typically associated with thunderstorms?',\n",
       "  'input': '',\n",
       "  'output': 'The type of cloud typically associated with thunderstorms is cumulonimbus.',\n",
       "  'model_response': 'The type of cloud associated with thunderstorms is a cumulus cloud.'},\n",
       " {'instruction': \"Name the author of 'Pride and Prejudice'.\",\n",
       "  'input': '',\n",
       "  'output': 'Jane Austen.',\n",
       "  'model_response': \"The author of 'Pride and Prejudice' is Jane Austen.\"},\n",
       " {'instruction': 'What is the periodic symbol for chlorine?',\n",
       "  'input': '',\n",
       "  'output': 'The periodic symbol for chlorine is Cl.',\n",
       "  'model_response': 'The periodic symbol for chlorine is CH3.'},\n",
       " {'instruction': 'Correct the punctuation in the sentence.',\n",
       "  'input': 'Its time to go home.',\n",
       "  'output': \"The corrected sentence should be: 'It's time to go home.'\",\n",
       "  'model_response': \"It's time to go home.\"},\n",
       " {'instruction': 'Rewrite the sentence.',\n",
       "  'input': 'The lecture was delivered in a clear manner.',\n",
       "  'output': 'The lecture was delivered clearly.',\n",
       "  'model_response': 'The lecture was delivered in a clear manner.'},\n",
       " {'instruction': 'Generate a humorous anecdote.',\n",
       "  'input': '',\n",
       "  'output': 'Why was the math book sad? Because it had too many problems!',\n",
       "  'model_response': 'I was at a party last night. A few friends were having a good time. One of them said, \"I just got a new job.\" I replied, \"What do you mean you just got a new job?\" He replied, \"I just got a new job.\"'},\n",
       " {'instruction': \"Identify the correct spelling: 'recieve' or 'receive'.\",\n",
       "  'input': '',\n",
       "  'output': \"The correct spelling is 'receive'.\",\n",
       "  'model_response': \"The correct spelling is 'receive'.\"},\n",
       " {'instruction': \"Create a sentence using the word 'nostalgia'.\",\n",
       "  'input': '',\n",
       "  'output': 'Nostalgia washed over her as she looked through the old photos.',\n",
       "  'model_response': 'I was very nostalgic for my childhood.'},\n",
       " {'instruction': 'Classify the following numbers as prime or composite.',\n",
       "  'input': ': 11, 14, 19.',\n",
       "  'output': 'Prime numbers: 11, 19\\nComposite numbers: 14',\n",
       "  'model_response': 'Prime numbers: 11, 14, 19\\nComposite numbers: 19'},\n",
       " {'instruction': 'What is the capital of Denmark?',\n",
       "  'input': '',\n",
       "  'output': 'The capital of Denmark is Copenhagen.',\n",
       "  'model_response': 'The capital of Denmark is Copenhagen.'},\n",
       " {'instruction': \"What is the opposite of 'wet'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'wet' is 'dry'.\",\n",
       "  'model_response': \"The opposite of 'wet' is 'dry'.\"},\n",
       " {'instruction': 'Identify the type of sentence.',\n",
       "  'input': 'Did you finish the report?',\n",
       "  'output': 'The type of sentence is interrogative.',\n",
       "  'model_response': 'The type of sentence is imperative.'},\n",
       " {'instruction': 'What is the chemical symbol for mercury?',\n",
       "  'input': '',\n",
       "  'output': 'Hg.',\n",
       "  'model_response': 'The chemical symbol for mercury is Hg.'},\n",
       " {'instruction': 'Describe the process of active transport in cells.',\n",
       "  'input': '',\n",
       "  'output': 'Active transport is the movement of molecules across a cell membrane from a region of lower concentration to a region of higher concentration, using energy in the form of ATP. This process is crucial for maintaining cellular homeostasis.',\n",
       "  'model_response': 'Transport in cells is the movement of substances through the medium of an ionic liquid.'},\n",
       " {'instruction': 'Classify the following items as either solid, liquid, or gas.',\n",
       "  'input': 'Mercury, oxygen, wood',\n",
       "  'output': 'Mercury - Liquid\\nOxygen - Gas\\nWood - Solid',\n",
       "  'model_response': 'Solid: Mercury\\nLiquid: Oxygen\\nGas: Wood'},\n",
       " {'instruction': 'Convert 3 kilometers to meters.',\n",
       "  'input': '',\n",
       "  'output': '3 kilometers is 3000 meters.',\n",
       "  'model_response': '3 kilometers is 3000 meters.'},\n",
       " {'instruction': 'Convert the sentence to use an indefinite pronoun.',\n",
       "  'input': 'Someone left a note.',\n",
       "  'output': 'A note was left by someone.',\n",
       "  'model_response': 'A note was left by someone.'},\n",
       " {'instruction': \"Provide a synonym for 'excited'.\",\n",
       "  'input': '',\n",
       "  'output': \"A synonym for 'excited' is 'thrilled'.\",\n",
       "  'model_response': \"A synonym for 'excited' is 'enthusiastic'.\"},\n",
       " {'instruction': 'Generate a sentence that follows the pattern: \"Never have I ever _____ without _____\"',\n",
       "  'input': '',\n",
       "  'output': 'Never have I ever traveled without a map.',\n",
       "  'model_response': 'Never have I ever had without having.'},\n",
       " {'instruction': 'Pick out the adjective from the following list.',\n",
       "  'input': 'run, tall, quickly',\n",
       "  'output': \"The correct adjective from the list is 'tall.'\",\n",
       "  'model_response': \"The adjective from the list is 'quick'.\"},\n",
       " {'instruction': 'Convert 1000 grams to kilograms.',\n",
       "  'input': '',\n",
       "  'output': '1000 grams is equal to 1 kilogram.',\n",
       "  'model_response': '1000 grams is 0.1 kilograms.'},\n",
       " {'instruction': \"What is the opposite of 'deep'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'deep' is 'shallow'.\",\n",
       "  'model_response': \"The opposite of 'deep' is 'light'.\"},\n",
       " {'instruction': 'Categorize the given list of animals.',\n",
       "  'input': 'Shark, Dolphin, Trout',\n",
       "  'output': 'Fish: Shark, Trout\\nMammals: Dolphin',\n",
       "  'model_response': 'Animals in the list: Shark, Dolphin, Trout'},\n",
       " {'instruction': \"Translate 'library' into Spanish.\",\n",
       "  'input': '',\n",
       "  'output': \"The Spanish word for 'library' is 'biblioteca'.\",\n",
       "  'model_response': \"The Spanish translation of 'library' is 'libraries'.\"},\n",
       " {'instruction': \"Define the term 'hyperbole'.\",\n",
       "  'input': '',\n",
       "  'output': 'Hyperbole is a figure of speech that involves an exaggeration of ideas for the sake of emphasis.',\n",
       "  'model_response': 'Hyperbole is a word used to describe a statement that is exaggerated or exaggerated in order to make it more dramatic or dramaticistic.'},\n",
       " {'instruction': \"Translate 'Hello' into Russian.\",\n",
       "  'input': '',\n",
       "  'output': 'Привет (Privet)',\n",
       "  'model_response': \"The Russian translation of 'Hello' is 'Русский просторавляет' (Русский просторавляет проставляет).\"},\n",
       " {'instruction': \"Define the term 'kinetic energy'.\",\n",
       "  'input': '',\n",
       "  'output': 'Kinetic energy is the energy that an object possesses due to its motion.',\n",
       "  'model_response': 'Kinetic energy is the force that causes an object to accelerate or decelerate in response to an applied force.'},\n",
       " {'instruction': \"What is the opposite of 'hot'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'hot' is 'cold'.\",\n",
       "  'model_response': \"The opposite of 'hot' is 'cold'.\"},\n",
       " {'instruction': 'Convert 5 miles to kilometers.',\n",
       "  'input': '',\n",
       "  'output': '5 miles is approximately 8.05 kilometers.',\n",
       "  'model_response': '5 miles is 5000 meters.'},\n",
       " {'instruction': 'What is the chemical formula for magnesium sulfate?',\n",
       "  'input': '',\n",
       "  'output': 'The chemical formula for magnesium sulfate is MgSO4.',\n",
       "  'model_response': 'The chemical formula for magnesium sulfate is MgSO4.'},\n",
       " {'instruction': 'Rewrite the following sentence to replace any cliché phrases.',\n",
       "  'input': \"It's a piece of cake\",\n",
       "  'output': \"It's very easy.\",\n",
       "  'model_response': '.\\n\\n\\nA piece of cake is a cake.'},\n",
       " {'instruction': 'List five different types of vegetables.',\n",
       "  'input': '',\n",
       "  'output': '1. Carrot\\n2. Broccoli\\n3. Cucumber\\n4. Tomato\\n5. Spinach',\n",
       "  'model_response': '1. Broccoli\\n2. Cucumber\\n3. Spinach\\n4. Tomato\\n5. Spinach, Cucumber, and Tomato'},\n",
       " {'instruction': 'Convert 7 kilometers to meters.',\n",
       "  'input': '',\n",
       "  'output': '7 kilometers is 7000 meters.',\n",
       "  'model_response': '7 kilometers is 7.07 miles.'},\n",
       " {'instruction': \"What is the opposite of 'heavy'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'heavy' is 'light'.\",\n",
       "  'model_response': \"The opposite of 'heavy' is 'light'.\"},\n",
       " {'instruction': \"What is the past tense of 'sing'?\",\n",
       "  'input': '',\n",
       "  'output': \"The past tense of 'sing' is 'sang.'\",\n",
       "  'model_response': \"The past tense of 'sing' is 'to sing.'\"},\n",
       " {'instruction': 'What is the molecular formula for carbon dioxide?',\n",
       "  'input': '',\n",
       "  'output': 'The molecular formula for carbon dioxide is CO2.',\n",
       "  'model_response': 'The molecular formula for carbon dioxide is CO2.'},\n",
       " {'instruction': 'Convert this sentence to passive voice',\n",
       "  'input': 'The gardener watered the plants.',\n",
       "  'output': 'The plants were watered by the gardener.',\n",
       "  'model_response': 'The plants were watered by the gardener.'},\n",
       " {'instruction': \"What is the past tense of 'throw'?\",\n",
       "  'input': '',\n",
       "  'output': \"The past tense of 'throw' is 'threw'.\",\n",
       "  'model_response': \"The past tense of 'throw' is 'threw'.\"},\n",
       " {'instruction': 'Explain what a sonnet is.',\n",
       "  'input': '',\n",
       "  'output': 'A sonnet is a 14-line poem with a specific rhyme scheme and meter, often written in iambic pentameter.',\n",
       "  'model_response': \"A sonnet is a poem that begins with the words 'I sing.'\"},\n",
       " {'instruction': \"Generate a sentence using the word 'innovative'.\",\n",
       "  'input': '',\n",
       "  'output': 'The company is known for its innovative products.',\n",
       "  'model_response': 'She was very innovative and always had a smile on her face.'},\n",
       " {'instruction': \"Provide the plural form of 'cactus'.\",\n",
       "  'input': '',\n",
       "  'output': \"The plural form of 'cactus' is 'cacti'.\",\n",
       "  'model_response': \"The plural form of 'cactus' is 'cacti'.\"},\n",
       " {'instruction': \"Translate the phrase 'Where is the bathroom?' into German.\",\n",
       "  'input': '',\n",
       "  'output': \"The German translation of 'Where is the bathroom?' is 'Wo ist die Toilette?'\",\n",
       "  'model_response': \"The German translation of 'Where is the bathroom?' is 'Wie es über?'.\"},\n",
       " {'instruction': 'Generate a past-tense verb that describes a person laughing.',\n",
       "  'input': '',\n",
       "  'output': 'Laughed.',\n",
       "  'model_response': 'He laughed.'},\n",
       " {'instruction': \"Generate a sentence using the word 'transient.'\",\n",
       "  'input': '',\n",
       "  'output': 'The transient nature of her visit left a lasting impression.',\n",
       "  'model_response': 'She was transported from the park to the library.'},\n",
       " {'instruction': \"Generate a sentence using the word 'optimistic'.\",\n",
       "  'input': '',\n",
       "  'output': 'He remained optimistic despite the challenges he faced.',\n",
       "  'model_response': 'She was optimistic about the future.'},\n",
       " {'instruction': 'Re-word this sentence using an indirect question.',\n",
       "  'input': 'What time is the meeting?',\n",
       "  'output': 'Could you tell me what time the meeting is?',\n",
       "  'model_response': 'The meeting is at 7:00.'},\n",
       " {'instruction': 'Categorize the following sentence as a statement, a question, or an exclamation.',\n",
       "  'input': 'What a beautiful day!',\n",
       "  'output': 'Exclamation.',\n",
       "  'model_response': 'A statement.'},\n",
       " {'instruction': \"What is the opposite of 'rich'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'rich' is 'poor'.\",\n",
       "  'model_response': \"The opposite of 'rich' is 'poor'.\"},\n",
       " {'instruction': 'Find a synonym for the given verb.',\n",
       "  'input': 'Begin',\n",
       "  'output': 'Commence',\n",
       "  'model_response': 'Begin'},\n",
       " {'instruction': 'Edit the given text to ensure all plural nouns are spelled correctly.',\n",
       "  'input': 'The birds sings beautiful songs.',\n",
       "  'output': 'The birds sing beautiful songs.',\n",
       "  'model_response': 'The birds sings beautiful songs.'},\n",
       " {'instruction': 'Transform the following sentence into a question using \"could.\"',\n",
       "  'input': 'You can help me tomorrow.',\n",
       "  'output': 'Could you help me tomorrow?',\n",
       "  'model_response': 'Could you help me tomorrow?'},\n",
       " {'instruction': 'Classify the following items: bicycle, rose, tiger.',\n",
       "  'input': '',\n",
       "  'output': 'Vehicles: Bicycle\\nPlants: Rose\\nAnimals: Tiger',\n",
       "  'model_response': 'Animals: Tiger\\nPlants: Rose\\nPlants: Bicycle\\nAnimals: Tiger\\nPlants: Rose\\nPlants: Bicycle'},\n",
       " {'instruction': \"Define the term 'irony'.\",\n",
       "  'input': '',\n",
       "  'output': 'Irony is a figure of speech in which words are used in such a way that their intended meaning is different from the actual meaning of the words.',\n",
       "  'model_response': \"The term 'irony' is a synonym for 'silly'.\"},\n",
       " {'instruction': \"Translate 'Welcome' into German.\",\n",
       "  'input': '',\n",
       "  'output': \"The German translation of 'Welcome' is 'Willkommen'.\",\n",
       "  'model_response': \"The German translation of 'Welcome' is 'Wie es tut mir?'.\"},\n",
       " {'instruction': 'Explain the primary function of the human heart.',\n",
       "  'input': '',\n",
       "  'output': 'The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.',\n",
       "  'model_response': 'The primary function of the human heart is to pump blood to the brain and to return carbon dioxide and oxygen to the body.'},\n",
       " {'instruction': 'Reword the following sentence to the future tense.',\n",
       "  'input': 'He is reading a novel inspired by his grandmother.',\n",
       "  'output': 'He will be reading a novel inspired by his grandmother.',\n",
       "  'model_response': 'He is reading a novel inspired by his grandmother.'},\n",
       " {'instruction': 'Convert the given sentence into active voice.',\n",
       "  'input': 'The law was passed by the government.',\n",
       "  'output': 'The government passed the law.',\n",
       "  'model_response': 'The law was passed by the government.'},\n",
       " {'instruction': \"Create a sentence using the word 'inevitable'.\",\n",
       "  'input': '',\n",
       "  'output': 'The confrontation was inevitable given the circumstances.',\n",
       "  'model_response': 'The storm was inevitable.'},\n",
       " {'instruction': 'Categorize the following sentence as either factual or opinion-based.',\n",
       "  'input': 'Chocolate is the best dessert.',\n",
       "  'output': 'Opinion-based.',\n",
       "  'model_response': 'Categorize the following sentence as either factual or opinion-based.'},\n",
       " {'instruction': \"What is an antonym of 'old'?\",\n",
       "  'input': '',\n",
       "  'output': 'young.',\n",
       "  'model_response': \"An antonym of 'old' is 'young'.\"},\n",
       " {'instruction': \"Provide a synonym for 'hardworking'.\",\n",
       "  'input': '',\n",
       "  'output': \"A synonym for 'hardworking' is 'diligent'.\",\n",
       "  'model_response': \"A synonym for 'hardworking' is 'smart'.\"},\n",
       " {'instruction': 'What is the boiling point of sulfur in Celsius?',\n",
       "  'input': '',\n",
       "  'output': 'The boiling point of sulfur is 444.6 degrees Celsius.',\n",
       "  'model_response': 'The boiling point of sulfur is -114.5 degrees Celsius.'},\n",
       " {'instruction': \"What is the plural form of 'child'?\",\n",
       "  'input': '',\n",
       "  'output': \"The plural form of 'child' is 'children'.\",\n",
       "  'model_response': \"The plural form of 'child' is 'chunk'.\"},\n",
       " {'instruction': \"What is an antonym of 'complicated'?\",\n",
       "  'input': '',\n",
       "  'output': \"An antonym of 'complicated' is 'simple'.\",\n",
       "  'model_response': \"An antonym of 'complicated' is 'easy'.\"},\n",
       " {'instruction': 'Name three forms of water.',\n",
       "  'input': '',\n",
       "  'output': 'The three forms of water are solid (ice), liquid (water), and gas (steam).',\n",
       "  'model_response': 'Three forms of water are water vapor, water, and water vapor.'},\n",
       " {'instruction': 'Rewrite this sentence as a question.',\n",
       "  'input': 'The dog chased the cat.',\n",
       "  'output': 'Did the dog chase the cat?',\n",
       "  'model_response': 'What is the name of the cat?'},\n",
       " {'instruction': \"Split the following sentence into two declarative sentences: 'The movie was long but interesting.'\",\n",
       "  'input': '',\n",
       "  'output': 'The movie was long. It was interesting.',\n",
       "  'model_response': 'The movie was long but interesting.'},\n",
       " {'instruction': 'Classify the following substances as acid, base, or neutral.',\n",
       "  'input': 'Lemon juice, Soap, Water',\n",
       "  'output': 'Acid: Lemon juice\\nBase: Soap\\nNeutral: Water',\n",
       "  'model_response': 'Acid: Soap\\nBase: Soap\\nNegative: Water'},\n",
       " {'instruction': \"What is a synonym of 'sad'?\",\n",
       "  'input': '',\n",
       "  'output': \"A synonym for 'sad' is 'unhappy'.\",\n",
       "  'model_response': \"A synonym for 'sad' is 'angry'.\"},\n",
       " {'instruction': 'Correct any spelling mistakes in the given sentence.',\n",
       "  'input': 'I prefer homemade cookies to store boaght.',\n",
       "  'output': 'I prefer homemade cookies to store bought.',\n",
       "  'model_response': 'I prefer homemade cookies to store boaght.'},\n",
       " {'instruction': \"Generate a sentence using the word 'transient'.\",\n",
       "  'input': '',\n",
       "  'output': 'His stay in the city was transient, lasting only a couple of days.',\n",
       "  'model_response': 'She was transported from the park to the library.'},\n",
       " {'instruction': \"Translate 'I am lost' into Italian.\",\n",
       "  'input': '',\n",
       "  'output': \"The Italian translation of 'I am lost' is 'Mi sono perso' (if male) or 'Mi sono persa' (if female).\",\n",
       "  'model_response': 'Il più più?'},\n",
       " {'instruction': 'Classify this text as a technical document or a narrative.',\n",
       "  'input': 'This manual provides instructions for installing the software.',\n",
       "  'output': 'Technical document',\n",
       "  'model_response': 'Technical document.'},\n",
       " {'instruction': 'Sort the following list in descending order.',\n",
       "  'input': '10, 2, 25, 16, 7',\n",
       "  'output': '25, 16, 10, 7, 2.',\n",
       "  'model_response': ', 3, 3.\\n\\n\\nThe list of 25 is in ascending order.'},\n",
       " {'instruction': \"Translate 'Can I have some water?' into French.\",\n",
       "  'input': '',\n",
       "  'output': \"Puis-je avoir de l'eau?\",\n",
       "  'model_response': 'Can I have some water?'},\n",
       " {'instruction': \"Create a simile with the word 'as cold as'.\",\n",
       "  'input': '',\n",
       "  'output': 'Her hands were as cold as ice.',\n",
       "  'model_response': \"The temperature of 'as cold as' is -38 degrees Celsius.\"},\n",
       " {'instruction': 'Classify the following words by their grammatical categories: swim, beautiful, quickly',\n",
       "  'input': '',\n",
       "  'output': 'Swim: Verb\\nBeautiful: Adjective\\nQuickly: Adverb',\n",
       "  'model_response': '.\\n\\n\\nThe following words are in the following grammatical categories: Verb, Adjective, Adverb, Adverbial, Adjective Adverb, Adverb\\n\\n### Input:\\nswim\\n\\n\\nThe following words are in the following grammatical categories: Adjective, Adverb, Adverb, Adverb'},\n",
       " {'instruction': 'Calculate the density of an object with a mass of 15 grams and a volume of 5 cubic centimeters.',\n",
       "  'input': '',\n",
       "  'output': 'The density of the object is 3 grams per cubic centimeter.',\n",
       "  'model_response': 'The density of the object is 15 grams/cc.'},\n",
       " {'instruction': \"What is the abbreviation for 'Master of Business Administration'?\",\n",
       "  'input': '',\n",
       "  'output': \"The abbreviation for 'Master of Business Administration' is MBA.\",\n",
       "  'model_response': \"The abbreviation for 'Master of Business Administration' is MBA.\"},\n",
       " {'instruction': 'Convert the following number from Roman numerals: IX.',\n",
       "  'input': '',\n",
       "  'output': 'The number IX in Roman numerals is 9.',\n",
       "  'model_response': '5 to decimal: 1.5.\\n\\n\\n1.5 is a Roman numeral.'},\n",
       " {'instruction': \"What is the opposite of 'horizontal'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'horizontal' is 'vertical'.\",\n",
       "  'model_response': \"The opposite of 'horizontal' is 'vertical'.\"},\n",
       " {'instruction': \"Translate 'Where can I buy tickets?' into Italian.\",\n",
       "  'input': '',\n",
       "  'output': \"The Italian translation for 'Where can I buy tickets?' is 'Dove posso comprare i biglietti?'\",\n",
       "  'model_response': \"The Italian translation of 'Where can I buy tickets?' is 'Ti amo?'.\"},\n",
       " {'instruction': 'Rewrite the following sentence to replace any clichés.',\n",
       "  'input': 'He was as cool as a cucumber.',\n",
       "  'output': 'He remained very calm.',\n",
       "  'model_response': 'He was as cool as a cucumber.'},\n",
       " {'instruction': 'Identify the main verb in the sentence.',\n",
       "  'input': 'The dog barked loudly.',\n",
       "  'output': \"The main verb in the sentence is 'barked'.\",\n",
       "  'model_response': \"The main verb in the sentence is 'bark'.\"},\n",
       " {'instruction': \"Generate a sentence using the word 'elucidate'.\",\n",
       "  'input': '',\n",
       "  'output': 'The professor attempted to elucidate the complex topic for his students.',\n",
       "  'model_response': 'The teacher had studied the book for a long time.'},\n",
       " {'instruction': 'Correct the sentence.',\n",
       "  'input': 'Me and my friend went to the store.',\n",
       "  'output': 'My friend and I went to the store.',\n",
       "  'model_response': 'We went to the store.'},\n",
       " {'instruction': 'What is the formula for calculating work done?',\n",
       "  'input': '',\n",
       "  'output': 'The formula for calculating work done is work = force × distance.',\n",
       "  'model_response': 'The formula for calculating work done is W = (1 - H)2 + (1 - C)3 + (1 - D)4 + (1 - E)5 + (1 - F)6 + (1 - G)7 + (1 - H)8 + (1 - I)9 + (1 - J)10 + (1 - K)11 + (1 - L)12 + (1 - M)13 + (1 - N)14 + (1 - O)15 + (1 - P)16 + (1 - Q)17 + (1 - R)18 + (1 - S)19 + (1 - T)20 + (1 - U)21 + (1 - V)22 + (1 - W)23 + (1 - X)24 + (1 - Y)25 + (1 - Z)26 + (1 - W)27 + (1 - X)28 + (1 - Y)29 + (1 - Z)30 + (1 - W)31 + (1 - X)32 + (1 - Y)33 + (1 - Z)34 + (1 - W)35 + (1 -'},\n",
       " {'instruction': 'What is the chemical formula for ammonium nitrate?',\n",
       "  'input': '',\n",
       "  'output': 'The chemical formula for ammonium nitrate is NH4NO3.',\n",
       "  'model_response': 'The chemical formula for ammonium nitrate is NH3.'},\n",
       " {'instruction': 'What is the molecular formula for water?',\n",
       "  'input': '',\n",
       "  'output': 'The molecular formula for water is H2O.',\n",
       "  'model_response': 'The molecular formula for water is H2O2.'},\n",
       " {'instruction': 'Rewrite the given sentence to describe the same thing in a positive way.',\n",
       "  'input': 'The food was not good.',\n",
       "  'output': 'The food could use some improvement.',\n",
       "  'model_response': 'The food was not good.'},\n",
       " {'instruction': \"What is the opposite of 'lazy'?\",\n",
       "  'input': '',\n",
       "  'output': \"The opposite of 'lazy' is 'diligent'.\",\n",
       "  'model_response': \"The opposite of 'lazy' is 'attentive'.\"},\n",
       " {'instruction': 'Name three essential vitamins for human health.',\n",
       "  'input': '',\n",
       "  'output': '1. Vitamin A\\n2. Vitamin C\\n3. Vitamin D',\n",
       "  'model_response': '1. Vitamin B12\\n2. Vitamin C\\n3. Vitamin B6'},\n",
       " {'instruction': \"Define the term 'simile'.\",\n",
       "  'input': '',\n",
       "  'output': \"A simile is a figure of speech that directly compares two different things, often introduced with the words 'like' or 'as'.\",\n",
       "  'model_response': 'A simile is a figurative device used to describe a thing or idea.'},\n",
       " {'instruction': 'What is the boiling point of chlorine in Celsius?',\n",
       "  'input': '',\n",
       "  'output': 'The boiling point of chlorine is -34 degrees Celsius.',\n",
       "  'model_response': 'The boiling point of chlorine is -196.5 degrees Celsius.'},\n",
       " {'instruction': \"Translate 'My name is' into French.\",\n",
       "  'input': '',\n",
       "  'output': \"The French translation of 'My name is' is 'Je m'appelle'.\",\n",
       "  'model_response': \"The French translation of 'My name is' is 'Comment ça va?'.\"},\n",
       " {'instruction': 'Convert 200 centimeters to meters.',\n",
       "  'input': '',\n",
       "  'output': '200 centimeters is 2 meters.',\n",
       "  'model_response': '200 centimeters is 0.2 meters.'},\n",
       " {'instruction': 'What is the chemical symbol for zinc?',\n",
       "  'input': '',\n",
       "  'output': 'Zn.',\n",
       "  'model_response': 'The chemical symbol for zinc is Zn.'},\n",
       " {'instruction': 'What is the formula for calculating force?',\n",
       "  'input': '',\n",
       "  'output': 'The formula for calculating force is Force = mass x acceleration.',\n",
       "  'model_response': 'The formula for calculating force is (F = mv² + g)f, where m is mass and g is acceleration.'},\n",
       " {'instruction': \"Generate a sentence using the word 'innovative'.\",\n",
       "  'input': '',\n",
       "  'output': \"The company's innovative approach set it apart from its competitors.\",\n",
       "  'model_response': 'She was very innovative and always had a smile on her face.'},\n",
       " {'instruction': \"Generate a sentence using the word 'generous'.\",\n",
       "  'input': '',\n",
       "  'output': 'He is very generous and always helps those in need.',\n",
       "  'model_response': 'She was very generous and gave the poor man a present.'},\n",
       " {'instruction': \"What is an antonym of 'sharp'?\",\n",
       "  'input': '',\n",
       "  'output': \"An antonym of 'sharp' is 'dull'.\",\n",
       "  'model_response': \"An antonym of 'sharp' is 'thin'.\"},\n",
       " {'instruction': 'Describe the basic structure of a neuron.',\n",
       "  'input': '',\n",
       "  'output': 'A neuron consists of three main parts: the cell body, which contains the nucleus; dendrites, which receive signals from other neurons; and an axon, which transmits signals to other neurons, muscles, or glands.',\n",
       "  'model_response': 'A neuron is a type of synapse in the brain.'},\n",
       " {'instruction': \"Translate 'see you later' into Spanish.\",\n",
       "  'input': '',\n",
       "  'output': 'Hasta luego',\n",
       "  'model_response': 'Están leyendo see you later.'},\n",
       " {'instruction': 'What are the first 10 elements of the Fibonacci sequence?',\n",
       "  'input': '',\n",
       "  'output': '0, 1, 1, 2, 3, 5, 8, 13, 21, 34.',\n",
       "  'model_response': 'The first 10 elements of the Fibonacci sequence are: 1, 3, 5, 7, 11, 13, 15, 21, 3, 5, 8, 11, 5, 3, 7, 9, 11.'},\n",
       " {'instruction': \"What is an antonym of 'transparent'?\",\n",
       "  'input': '',\n",
       "  'output': \"An antonym of 'transparent' is 'opaque'.\",\n",
       "  'model_response': \"An antonym of 'transparent' is 'illuminate'.\"},\n",
       " {'instruction': \"What is the past tense of 'think'?\",\n",
       "  'input': '',\n",
       "  'output': \"The past tense of 'think' is 'thought'.\",\n",
       "  'model_response': \"The past tense of 'think' is 'to think'.\"},\n",
       " {'instruction': 'Classify each sentence as either declarative, interrogative, imperative, or exclamatory.',\n",
       "  'input': 'Please open the door.',\n",
       "  'output': \"The classification of the sentence 'Please open the door.' is imperative.\",\n",
       "  'model_response': 'Please open the door.'},\n",
       " {'instruction': 'Rewrite the sentence to use a negative adverb.',\n",
       "  'input': 'She always remembers to call.',\n",
       "  'output': 'She never forgets to call.',\n",
       "  'model_response': 'She always remembers to call.'},\n",
       " {'instruction': 'Convert 50 miles per hour to kilometers per hour.',\n",
       "  'input': '',\n",
       "  'output': '50 miles per hour is approximately 80.47 kilometers per hour.',\n",
       "  'model_response': '50 miles per hour is approximately 32.5 kilometers per hour.'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_respnse\"] = response_text\n",
    "\n",
    "#with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    #json.dump(test_data, file, indent=4)\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "download_dataset(file_path, url_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "243d6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def check_if_running(process_name):\n",
    "  running = False\n",
    "  for proc in psutil.process_iter([\"name\"]):\n",
    "    if process_name in proc.info[\"name\"]:\n",
    "      running = True\n",
    "      break\n",
    "  return running\n",
    "\n",
    "ollama_running = check_if_running(\"Ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "  raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\", check_if_running(\"Ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71be3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    request = urllib.request.Request(\n",
    "        url, \n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5fbf7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cheetahs are found in the wild in various parts of Africa and a small portion of Iran. Here's a breakdown of their geographic range:\n",
      "\n",
      "1. **Africa**: Cheetahs are widely distributed across sub-Saharan Africa, including:\n",
      "\t* South Africa: Kruger National Park, Pilanesberg Game Reserve, and other protected areas.\n",
      "\t* Namibia: Etosha National Park, Namib-Naukluft National Park, and other game reserves.\n",
      "\t* Botswana: Chobe National Park, Okavango Delta, and other national parks and game reserves.\n",
      "\t* Kenya: Masai Mara National Reserve, Amboseli National Park, and other protected areas.\n",
      "\t* Tanzania: Serengeti National Park, Ngorongoro Conservation Area, and other national parks and game reserves.\n",
      "\t* Mozambique: Gorongosa National Park and other protected areas.\n",
      "2. **Iran**: A small population of cheetahs is found in the central plateau region of Iran, particularly in:\n",
      "\t* Kavir National Park\n",
      "\t* Yazd Province\n",
      "\n",
      "It's worth noting that cheetahs are an endangered species, and their populations are declining due to habitat loss, human-wildlife conflict, poaching, and other threats. Conservation efforts are underway to protect these magnificent animals and their habitats.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3\"\n",
    "result = query_model(\"Where do cheetahs live?\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9e4b1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "Score:\n",
      "f>> I'd be happy to help!\n",
      "\n",
      "Here's my attempt at rewriting the sentence using a simile:\n",
      "\n",
      "The car is as fast as lightning.\n",
      "\n",
      "And I'll score The car is as fast as a cheetah. on a scale from 0 to 100, where 100 is the best score.\n",
      "\n",
      "Score: 60\n",
      "\n",
      "Reasoning: While \"as fast as a cheetah\" is a good simile, it's not as vivid or unexpected as \"as fast as lightning\". Lightning is often associated with speed and suddenness, making it a more evocative comparison.\n",
      "\n",
      "-------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of cloud.\n",
      "\n",
      "Score:\n",
      "f>> ### Model Response\n",
      "The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "### Score: 90\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "* The model response accurately answers the question by specifying that cumulonimbus clouds are typically associated with thunderstorms.\n",
      "* The response is concise and clear, making it easy to understand.\n",
      "* However, the score is not a perfect 100 because the model response does not provide additional context or explanation about why cumulonimbus clouds are associated with thunderstorms.\n",
      "\n",
      "-------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Score:\n",
      "f>> ### Response\n",
      "The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "### Score: 100\n",
      "\n",
      "My response perfectly matches the instruction, correctly identifying the author of 'Pride and Prejudice' as Jane Austen. Therefore, I give myself a score of 100!\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input {format_input(entry)} \"\n",
    "        f\"and correct output {entry['output']}, \"\n",
    "        f\"score the model response {entry['model_respnse']} \"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(f\">> {entry['output']}\")\n",
    "    print(\"\\nModel response:\")\n",
    "    print(f\">> {entry['model_respnse']}\")\n",
    "    print(\"\\nScore:\")\n",
    "    print(f\"f>> {query_model(prompt)}\")\n",
    "    print(\"\\n-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input {format_input(entry)} \"\n",
    "            f\"and correct output {entry['output']}, \"\n",
    "            f\"score the model response {entry[json_key]}\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "    return scores\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_built_steps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6fe106",
   "metadata": {},
   "source": [
    "# Lecture 17.1: Multi-Head-Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a517cdf",
   "metadata": {},
   "source": [
    "### extension of the causal attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "832a1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "inputs = torch.tensor([[0.43, 0.15, 0.89],\n",
    "                       [0.55, 0.87, 0.66],\n",
    "                       [0.57, 0.85, 0.64],\n",
    "                       [0.22, 0.58, 0.33],\n",
    "                       [0.77, 0.25, 0.10],\n",
    "                       [0.05, 0.80, 0.55]]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebcfe80",
   "metadata": {},
   "source": [
    "### defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb2c799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Length: 6\n",
      "Input Dimension: 3\n",
      "Output Dimension: 2\n"
     ]
    }
   ],
   "source": [
    "context_length = inputs.shape[0]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "batch = torch.stack((inputs, inputs, inputs), dim=0)\n",
    "context_length = batch.shape[1]\n",
    "dropout = 0.0\n",
    "num_heads = 3\n",
    "print(f\"Context Length: {context_length}\\nInput Dimension: {d_in}\\nOutput Dimension: {d_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9e783",
   "metadata": {},
   "source": [
    "# Redefining the Causal-Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19344b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttentionV1(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d = x.shape\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)\n",
    "        attn_scores_masked = attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_scores_masked_scaled = attn_scores_masked / torch.sqrt(torch.tensor(keys.shape[-1]))\n",
    "        attn_weights = torch.softmax(attn_scores_masked_scaled, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_matrix = attn_weights @ values\n",
    "        return context_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe85f1",
   "metadata": {},
   "source": [
    "### creating an instance of the causal attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f2cdc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "causal_attention = CausalAttentionV1(d_in, d_out, context_length, 0.0)\n",
    "print(causal_attention.forward(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d25b4",
   "metadata": {},
   "source": [
    "# Multi-Head-Attention Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42cde094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            CausalAttentionV1(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa972b45",
   "metadata": {},
   "source": [
    "### creating an instance of the multi head attention wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e7d8368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4519,  0.2216,  0.4772,  0.1063,  0.4566,  0.2729],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257,  0.5792,  0.3011],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860,  0.6249,  0.3102],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589,  0.5691,  0.2785],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428,  0.5543,  0.2520],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493,  0.5337,  0.2499]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063,  0.4566,  0.2729],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257,  0.5792,  0.3011],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860,  0.6249,  0.3102],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589,  0.5691,  0.2785],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428,  0.5543,  0.2520],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493,  0.5337,  0.2499]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063,  0.4566,  0.2729],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257,  0.5792,  0.3011],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860,  0.6249,  0.3102],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589,  0.5691,  0.2785],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428,  0.5543,  0.2520],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493,  0.5337,  0.2499]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "torch.Size([3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "multi_head_attention = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout, num_heads)\n",
    "context_matrix = multi_head_attention.forward(batch)\n",
    "print(f\"{context_matrix}\\n{context_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8a8dd",
   "metadata": {},
   "source": [
    "## 1st Dimension --> number of batches = 3\n",
    "## 2nd Dimension --> context length = number of tokens in the sequence = 6\n",
    "## 3rd Dimension --> output Dimension * Number of Heads 2 * 3 = 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_built_steps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
